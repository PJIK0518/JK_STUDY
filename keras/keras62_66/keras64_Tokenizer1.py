# 범주형 데이터의 수치화는 LabelEncoder로 가능하지만 자연어는??

import numpy as np
import pandas as pd

from tensorflow.keras.preprocessing.text import Tokenizer

text = '오늘도 못 생기고 영어를 디게 디게 디게 못하는 이샥은 재미없는 개그를 \
        마구 마구 마구 마구하면서 딴짓을 한다'

# 영어의 경우에는 생각보다 간단하겠지만..?
# 한글의 경우에는 어절, 음정, 형태소 등으로 나눠서 진행

Token = Tokenizer()
Token.fit_on_texts([text])

""" print(Token.word_index) : 어절 단위로 잘라서
{'디게': 1, '마구': 2, '오늘도': 3, '못': 4, '생기고': 5,
 '영어를': 6, '못하는': 7, '이샥은': 8, '재미없는': 9,
 '개그를': 10, '마구하면서': 11, '딴짓을': 12, '한다': 13}
"""
""" print(Token.word_counts)
[('오늘도', 1), ('못', 1), ('생기고', 1), ('영어를', 1),
 ('디게', 3), ('못하는', 1), ('이샥은', 1), ('재미없는', 1), 
 '개그를', 1), ('마구', 3), ('마구하면서', 1), ('딴짓을', 1), ('한다', 1)] """
 
x = Token.texts_to_sequences([text])[0]
x = np.array(x)

# print(x) [3, 4, 5, 6, 1, 1, 1, 7, 8, 9, 10, 2, 2, 2, 11, 12, 13]
# print(x.shape) (17,)

""" 문장을 어절 단위로 수치화해서 순서대로 배열 >> RNN! """


############################
### OneHotEncoding
from sklearn.preprocessing import OneHotEncoder
x = np.array(x)

#1. pandas
# x = x - 1
# x = pd.get_dummies(x)
""" print(x)
print(x.shape)
    0   1   2   3   4   5   6   7   8   9   10  11  12
0    0   0   1   0   0   0   0   0   0   0   0   0   0
1    0   0   0   1   0   0   0   0   0   0   0   0   0
2    0   0   0   0   1   0   0   0   0   0   0   0   0
3    0   0   0   0   0   1   0   0   0   0   0   0   0
4    1   0   0   0   0   0   0   0   0   0   0   0   0
5    1   0   0   0   0   0   0   0   0   0   0   0   0
6    1   0   0   0   0   0   0   0   0   0   0   0   0
7    0   0   0   0   0   0   1   0   0   0   0   0   0
8    0   0   0   0   0   0   0   1   0   0   0   0   0
9    0   0   0   0   0   0   0   0   1   0   0   0   0
10   0   0   0   0   0   0   0   0   0   1   0   0   0
11   0   1   0   0   0   0   0   0   0   0   0   0   0
12   0   1   0   0   0   0   0   0   0   0   0   0   0
13   0   1   0   0   0   0   0   0   0   0   0   0   0
14   0   0   0   0   0   0   0   0   0   0   1   0   0
15   0   0   0   0   0   0   0   0   0   0   0   1   0
16   0   0   0   0   0   0   0   0   0   0   0   0   1
(17, 13)
"""

#2. sklearn
# x = x.reshape(-1,1)
# one = OneHotEncoder()
# x = one.fit_transform(x)
""" print(x)
print(x.shape)
  (0, 2)        1.0
  (1, 3)        1.0
  (2, 4)        1.0
  (3, 5)        1.0
  (4, 0)        1.0
  (5, 0)        1.0
  (6, 0)        1.0
  (7, 6)        1.0
  (8, 7)        1.0
  (9, 8)        1.0
  (10, 9)       1.0
  (11, 1)       1.0
  (12, 1)       1.0
  (13, 1)       1.0
  (14, 10)      1.0
  (15, 11)      1.0
  (16, 12)      1.0
(17, 13) """

#3. keras
from tensorflow.keras.utils import to_categorical

# x = x - 1
# x = to_categorical(x)

""" print(x)
print(x.shape)
[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]
(17, 13) """